By this week, your group should have a very simple version of an end-to-end pipeline with
preliminary results for a single model specification.

**Due Thursday, Feb. 20:** Technical modeling plan

In most cases, a vast array of methods — each with a number of tunable hyperparameters —
can be brought to bear on your modeling question. How do you decide which models are better than others and how can you be confident this decision will carry forward into the future
when the model is deployed? How should you balance considerations of performance and
fairness when making these decisions? Are models that are performing similarly well giving
similar predictions? What should you do if they are not? In this week, we’ll begin to answer
these questions, focusing on cross-validation stategies and choosing performance metrics.

Required Readings for Tuesday:

- Cross-validation strategies for data with temporal, spatial, hierarchical, or phylogenetic
structure by Roberts, DR, Bahn, V, et al. Ecography 40:2017. [Available Online](https://onlinelibrary.wiley.com/doi/pdf/10.1111/ecog.02881)
- The Secrets of Machine Learning by Rudin, C. and Carlson, D. arXiv preprint: 1906.01998.
2019. [Available Online](https://arxiv.org/abs/1906.01998)

Optional Readings:

- Big Data and Social Science edited by Foster, Ghani, et al. Chapter 5: Machine Learning.

